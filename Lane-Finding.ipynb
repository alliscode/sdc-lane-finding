{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting geometry.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile geometry.py\n",
    "\n",
    "class Point:\n",
    "    \"\"\"An imutable point class used to represent a 2 dimensional point in space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.__x = x\n",
    "        self.__y = y\n",
    "        \n",
    "    def __add__(self, *args):\n",
    "        \"\"\"Create a new point by adding to this one.\n",
    "        \n",
    "        Args:\n",
    "            args: May be an instance of Point or an array_like object with two number objects.\n",
    "            \n",
    "        Returns:\n",
    "            A new point object.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(args[0]) is type(Point):\n",
    "            return type(self)(self.x + args[0].x, self.y + args[0].y)\n",
    "        else:\n",
    "            return type(self)(self.x + args[0][0], self.y + args[0][1])\n",
    "        \n",
    "    def __subtract(self, point):\n",
    "        \"\"\"Create a new point by subtracting from this one.\n",
    "        \n",
    "        Args:\n",
    "            args: May be an instance of Point or an array_like object with two number objects.\n",
    "            \n",
    "        Returns:\n",
    "            A new point object.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(args[0]) is type(Point):\n",
    "            return type(self)(self.x - args[0].x, self.y - args[0].y)\n",
    "        else:\n",
    "            return type(self)(self.x - args[0][0], self.y - args[0][1])\n",
    "    \n",
    "    def __copy__(self):\n",
    "        return type(self)(self.x, self.y)\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        return type(self)(self.x, self.y)\n",
    "    \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self.__x\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.__y\n",
    "        \n",
    "class Size(Point):\n",
    "    \"\"\"An imutable size class used to represent the size of a 2 dimensional object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w, h):\n",
    "        Point.__init__(self, w, h)\n",
    "        \n",
    "    @property\n",
    "    def width(self):\n",
    "        return self.x\n",
    "        \n",
    "    @property\n",
    "    def height(self):\n",
    "        return self.y\n",
    "        \n",
    "class Rect:\n",
    "    \"\"\"An immutable rectangle class used to represent a rectangle in 2 dimensional space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, origin : Point, size : Size):\n",
    "        self.origin = origin\n",
    "        self.size = size\n",
    "        \n",
    "    def shift(self, amount : Point):\n",
    "        \"\"\"Creates a new Rect by shifting this one by the specified amount.\n",
    "        \n",
    "        Args:\n",
    "            amount: A point representing the amount to shift the origin of this rect by.\n",
    "            \n",
    "        Returns:\n",
    "            A new rect object.\n",
    "        \"\"\"\n",
    "        \n",
    "        return type(self)(self.origin + amount)\n",
    "        \n",
    "    def grow(self, amount : Size):\n",
    "        \"\"\"Creates a new Rect by growing this one by the specified amount.\n",
    "        \n",
    "        Args:\n",
    "            amount: A point representing the amount to grow the size of this rect by.\n",
    "            \n",
    "        Returns:\n",
    "            A new rect object.\n",
    "        \"\"\"\n",
    "        \n",
    "        return type(self)(self.size + amount)\n",
    "        \n",
    "    def __copy__(self):\n",
    "        return type(self)(self.origin, self.size)\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        return type(self)(self.origin, self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting camera.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile camera.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from geometry import *\n",
    "\n",
    "class Camera():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"A class that represents a camera. This object can be used to perform operations on images\n",
    "        associated with a given camera.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.m_distort = None\n",
    "        self.distortion_coeffs = None\n",
    "        self.birds_eye_t = None\n",
    "        self.birds_eye_t_inv = None\n",
    "    \n",
    "    def calibrateDistortion(self, chessboard_images, grid_size, min_examples=10):\n",
    "        \"\"\"Calibrates the camera instance using images of a chessboard with a known grid size.\n",
    "        \n",
    "        Note: I only expect 15 - 20 images to be provided so the array based approach is workable.\n",
    "        However, it may be better to provide an implementation that excepts a generator for the\n",
    "        images.\n",
    "        \n",
    "        Args:\n",
    "            chessboard_images: A numpy array of chessboard images.\n",
    "            grid_size: The grid size of the chessboard images : (x, y)\n",
    "            min_examples: The minimum number of successfully recognized chessboard images. If this\n",
    "                          minimum is not reached a ValueError is raised.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # create an array to represent the object point of each frame. This array represents the\n",
    "        # actual locations of the corners in each frame however the z coordinate is fixed at zero\n",
    "        frame_obj_points = np.zeros((grid_size[0]*grid_size[1], 3), np.float32)\n",
    "        frame_obj_points[:,:2] = np.mgrid[0:grid_size[0], 0:grid_size[1]].T.reshape(-1,2)\n",
    "        \n",
    "        # holders for the object and image points in each frame as well as images superimposed\n",
    "        # with chessboard corners\n",
    "        object_points = []\n",
    "        image_points = []\n",
    "        drawn_images = []\n",
    "        \n",
    "        for frame in chessboard_images:\n",
    "            \n",
    "            # convert to gray and find the chessboard corners\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, grid_size, None)\n",
    "            \n",
    "            # cv2 may fail to find the chessboard corners in the image that we provided and will set ret\n",
    "            # to False. In this case we just move on to the next frame.\n",
    "            if ret:\n",
    "                \n",
    "                # save the obj and img points as well as drawn frame\n",
    "                object_points.append(frame_obj_points)\n",
    "                image_points.append(corners)\n",
    "                drawn_images.append(cv2.drawChessboardCorners(frame, grid_size, corners, ret))\n",
    "            \n",
    "        # make sure we found the corners in enough frames\n",
    "        if len(drawn_images) < min_examples:\n",
    "            raise ValueError('Found corners in {0} frames, {0} required.'.format(len(drawn_images), min_examples))\n",
    "        \n",
    "        # now we use the obj and img points to create the camera matrix\n",
    "        ret, self.m_distort, self.distortion_coeffs, rvecs, tvecs = cv2.calibrateCamera(object_points, image_points, frame.shape[0:2] ,None, None)\n",
    "            \n",
    "        if not ret:\n",
    "            raise ValueError('Failed to find camera matrix from provided images.')\n",
    "            \n",
    "        return drawn_images\n",
    "    \n",
    "    def calibrateBirdsEye(self, src_points, dest_points):\n",
    "        \"\"\"Calibrates the camera for a birds-eye transformation.\n",
    "        \n",
    "        Args:\n",
    "            src_points: 4 points from the source image.\n",
    "            dest_points: 4 points that represent the transformed src_points.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.birds_eye_t = cv2.getPerspectiveTransform(src_points, dest_points)\n",
    "        self.birds_eye_t_inv = cv2.getPerspectiveTransform(dest_points, src_points)\n",
    "    \n",
    "    def undistortImage(self, image):\n",
    "        \"\"\"Undistorts the imput image using the matrix and distortion coefficients found during the\n",
    "        calibration. The camera must be calibrated before calling this.\n",
    "        \n",
    "        Args:\n",
    "            image: The image to transform.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure the calibration step has been performed\n",
    "        if self.m_distort is None or self.distortion_coeffs is None:\n",
    "            raise ValueError('The camera must be successfully calibrated before it can correct images')\n",
    "            \n",
    "        return cv2.undistort(image, self.m_distort, self.distortion_coeffs, None, None)\n",
    "    \n",
    "    def toBirdsEye(self, image):\n",
    "        \"\"\"Transform an imput image to a birds-eye view using the transformation found in the calibrateBirdsEye\n",
    "        step. The camera must be calibrated before calling this.\n",
    "        \n",
    "        Args:\n",
    "            image: The image to transform.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure the calibration step has been performed\n",
    "        if self.birds_eye_t is None:\n",
    "            raise ValueError('The camera must be calibrated for a birds eye view before it can transform images')\n",
    "            \n",
    "        return self.__warp__(image, self.birds_eye_t)\n",
    "    \n",
    "    def fromBirdsEye(self, image):\n",
    "        \"\"\"Transform an imput image from a birds-eye view using the inverse of the transformation found in the \n",
    "        calibrateBirdsEye step. The camera must be calibrated before calling this.\n",
    "        \n",
    "        Args:\n",
    "            image: The image to transform.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure the calibration step has been performed\n",
    "        if self.birds_eye_t is None:\n",
    "            raise ValueError('The camera must be calibrated for a birds eye view before it can transform images')\n",
    "            \n",
    "        return self.__warp__(image, self.birds_eye_t_inv)\n",
    "    \n",
    "    def __warp__(self, image, M):\n",
    "        # TODO: better way to reverse image shape?\n",
    "        return cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting road.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile road.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from collections import deque\n",
    "from copy import copy, deepcopy\n",
    "from geometry import *\n",
    "from camera import *\n",
    "import heapq\n",
    "from heapq import heappush, heappop\n",
    "import math\n",
    "\n",
    "class LaneLine:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"A class to represent a lane line.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.points = []\n",
    "        self.search_rects = []\n",
    "        self.fit_coefficients = None\n",
    "        self.fit_coefficients_world = None\n",
    "        self.baseCoordinate = None\n",
    "        self.hasVerifiedBaseCoordinate = False\n",
    "        self.__filter_rate = 0.2\n",
    "        \n",
    "    def __copy__(self):\n",
    "        new = type(self)(self.origin, self.size)\n",
    "        new.points = self.points\n",
    "        new.search_rects = self.search_rects\n",
    "        new.fit_coefficients = self.fit_ceofficients\n",
    "    \n",
    "    def __deepcopy__(self, memo):\n",
    "        new = type(self)(self.origin, self.size)\n",
    "        new.points = deepcopy(self.points)\n",
    "        new.search_rects = deepcopy(self.search_rects)\n",
    "        new.fit_coefficients = deepcopy(self.fit_ceofficients)\n",
    "        \n",
    "    @property\n",
    "    def points_x(self):\n",
    "        return [p.x for p in self.points]\n",
    "    \n",
    "    @property\n",
    "    def points_y(self):\n",
    "        return [p.y for p in self.points]\n",
    "        \n",
    "    def addPoint(self, point : Point):\n",
    "        \"\"\"Add a point to the lane line.\n",
    "        \n",
    "        Args:\n",
    "            point: The point to add to the lane line.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.points.append(point)\n",
    "        \n",
    "    def addSearcRect(self, rect : Rect):\n",
    "        \"\"\"Adds a search rect to the lane line.\n",
    "        \n",
    "        Args:\n",
    "            rect: The rect to add to the lane line.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.search_rects.append(rect)\n",
    "        \n",
    "    def fit(self, previous, x_scale, y_scale):\n",
    "        \"\"\"Fits the points in the line with a 2nd degree polynomial.\n",
    "        \n",
    "        Args: \n",
    "            previous_fit: The previous fit of the lane line. If provided, the current fit will be\n",
    "                          be used to update the previous fit as in a low pass filter. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # get fits in image space and world space\n",
    "        self.fit_coefficients = np.polyfit(self.points_y, self.points_x, 2)\n",
    "        self.fit_coefficients_world = np.polyfit(np.array(self.points_y)/y_scale, np.array(self.points_x)/x_scale, 2)\n",
    "        \n",
    "        # if a previous frame is provided, use it to low pass filter this one to help smooth out fluctuations\n",
    "        if previous is not None:\n",
    "            self.fit_coefficients = self.__filter_rate*self.fit_coefficients + (1-self.__filter_rate)*previous.fit_coefficients\n",
    "            self.fit_coefficients_world = self.__filter_rate*self.fit_coefficients_world + (1-self.__filter_rate)*previous.fit_coefficients_world\n",
    "        \n",
    "        return self.fit_coefficients\n",
    "    \n",
    "    def curvature(self, y):\n",
    "        \"\"\"Calculates the radius of curvature of the lane at a given point.\n",
    "        \n",
    "        Params:\n",
    "            y: The y point  at which to evaluate the radius of the lane.\n",
    "            \n",
    "        Returns:\n",
    "            The curvature of the lane at y. \n",
    "        \"\"\"\n",
    "        if self.fit_coefficients_world is None:\n",
    "            raise ValueError('The lane must be fit before calculating the curvature.')\n",
    "        \n",
    "        A, B = self.fit_coefficients_world[0], self.fit_coefficients_world[1]\n",
    "        return ((1 + (2*A*y + B)**2)**1.5) / (2*A)\n",
    "        \n",
    "    @classmethod\n",
    "    def fromBasePoint(cls, image, x_pos):\n",
    "        \"\"\"Creates a new LaneLine by starting at the bottom of the image and following the\n",
    "        lane up. The imput image must be a thresholded binary image that highlights the lanes.\n",
    "        \n",
    "        Args:\n",
    "            image: A thresholded binary image.\n",
    "            x_pos: The starting point at the bottom of the image.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # setup\n",
    "        box_height = 50\n",
    "        image_height = image.shape[0]\n",
    "        initial_box_width = 100\n",
    "        box_fanout = 30\n",
    "        avg_thresh = 0.01\n",
    "        num_rows = math.ceil(image_height/box_height)\n",
    "        lane = LaneLine()\n",
    "\n",
    "        # define the original search rect\n",
    "        origin = Point(int(max(x_pos-initial_box_width/2, 0)), int(image_height-1 - box_height))\n",
    "        box_size = Size(int(initial_box_width), int(box_height))\n",
    "        rect = Rect(origin, box_size)\n",
    "\n",
    "        # search each row\n",
    "        for row in range(num_rows-1):\n",
    "\n",
    "            # restate the rect coordinates in image space and slice the image\n",
    "            top, bottom = rect.origin.y, rect.origin.y + rect.size.height\n",
    "            left, right = rect.origin.x, rect.origin.x + rect.size.width\n",
    "            section = image[top:bottom, left:right]\n",
    "\n",
    "            # test if the current slice contains enough active pixels \n",
    "            if np.mean(section) > avg_thresh:\n",
    "\n",
    "                # use the center of mass (centroid) as location of the point within the line\n",
    "                cm = np.int32(ndimage.measurements.center_of_mass(section)[::-1])\n",
    "                found_point = rect.origin + cm\n",
    "                lane.addPoint(found_point)\n",
    "\n",
    "                # since we found a valid point, we reset the box size and move up a row\n",
    "                new_origin = Point(int(found_point.x - initial_box_width/2), max(rect.origin.y-box_height, 0))\n",
    "                new_size = Size(initial_box_width + 2*box_fanout, box_height)\n",
    "                \n",
    "                # update the base coordinate \n",
    "                if row == 0: \n",
    "                    lane.baseCoordinate = found_point.x\n",
    "                    lane.hasVerifiedBaseCoordinate = True\n",
    "\n",
    "            else:\n",
    "                # update the base coordinate\n",
    "                if row == 0:\n",
    "                    lane.baseCoordinate = x_pos\n",
    "                    lane.hasVerifiedBaseCoordinate = False\n",
    "                    lane.addPoint(Point(x_pos, image_height-1))\n",
    "\n",
    "                # since we did not find a valid point, we expand the search rect and move up a row.\n",
    "                # This expansion of the search grid with is required to handle curving lane lines\n",
    "                new_origin = Point(max(rect.origin.x - box_fanout, 0), max(rect.origin.y-box_height, 0))\n",
    "                new_size = Size(rect.size.width + 2*box_fanout, box_height)\n",
    "\n",
    "            # record the rect and adjust the for the next row\n",
    "            lane.addSearcRect(rect)\n",
    "            rect = Rect(new_origin, new_size)\n",
    "\n",
    "        return lane\n",
    "    \n",
    "    # Private helper methods\n",
    "    \n",
    "    @staticmethod\n",
    "    def normal8Bit(image):\n",
    "        retval = image - np.min(image)\n",
    "        return np.uint8(255 * retval/np.max(retval))\n",
    "\n",
    "    \n",
    "class Road:\n",
    "    \"\"\"A class to represent a road with 2 lane lines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, camera : Camera, x_scale=191, y_scale=25.7, lane_width=3.7):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            camera: The camera used to correct image distortion and warp them to a birds eye view.\n",
    "            x_scale: The scale of image coordinates to world coordinates. Measured in meters/pixel.\n",
    "        \"\"\"\n",
    "        self.camera = camera\n",
    "        self.l_history = deque()\n",
    "        self.r_history = deque()\n",
    "        self.currentLaneWidth = None\n",
    "        self.currentLaneOffset = None\n",
    "        self.currentLaneCurvature = None\n",
    "        self.currvatureDirection = None\n",
    "        self.__history_size = 5\n",
    "        self.__x_scale = x_scale\n",
    "        self.__y_scale = y_scale\n",
    "        self.__target_lane_width = lane_width\n",
    "        \n",
    "        # used for debug and reporting\n",
    "        self.base_map = None\n",
    "        \n",
    "    def clearHistory(self):\n",
    "        self.l_history = deque()\n",
    "        self.r_history = deque()\n",
    "    \n",
    "    def processFrame(self, image):\n",
    "        \"\"\"A method to process an image with the entire pipeline. This is the workhorse of the\n",
    "        road class.\n",
    "        \n",
    "        Args:\n",
    "            image: The image to be processed.\n",
    "            \n",
    "        Returns:\n",
    "            The original image with a green lane superimposed on top.\n",
    "        \"\"\"\n",
    "        \n",
    "        # run the image through the processing pipeline\n",
    "        corrected = self.camera.undistortImage(image)\n",
    "        birdsEye = self.camera.toBirdsEye(corrected)\n",
    "        thresholded = self.threshold(birdsEye)\n",
    "        l_base, r_base = self.findLaneBases(thresholded)\n",
    "        l_lane = LaneLine.fromBasePoint(thresholded, l_base)\n",
    "        r_lane = LaneLine.fromBasePoint(thresholded, r_base)\n",
    "        \n",
    "        # fit the lane lines\n",
    "        l_previous = self.l_history[-1] if len(self.l_history) > 0 else None\n",
    "        r_previous = self.r_history[-1] if len(self.r_history) > 0 else None\n",
    "        l_lane.fit(l_previous, self.__x_scale, self.__y_scale)\n",
    "        r_lane.fit(r_previous, self.__x_scale, self.__y_scale)\n",
    "        \n",
    "        # save some stats about the detected lines\n",
    "        self.currentLaneWidth = (r_lane.baseCoordinate - l_lane.baseCoordinate)\n",
    "        self.currentLaneOffset = (r_lane.baseCoordinate - image.shape[1]/2) - self.currentLaneWidth/2\n",
    "        self.currentLaneWidth /= self.__x_scale\n",
    "        self.currentLaneOffset /= self.__x_scale\n",
    "                \n",
    "        # save the current curvature\n",
    "        l_curvature = l_lane.curvature(image.shape[0])\n",
    "        r_curvature = r_lane.curvature(image.shape[0])\n",
    "        self.currentLaneCurvature = np.mean([l_curvature, r_curvature])\n",
    "        self.currvatureDirection = 'left' if self.currentLaneCurvature < 0 else 'right'\n",
    "        \n",
    "        # save the history\n",
    "        self.l_history.append(l_lane)\n",
    "        if len(self.l_history) > self.__history_size : self.l_history.popleft()\n",
    "            \n",
    "        self.r_history.append(r_lane)\n",
    "        if len(self.r_history) > self.__history_size : self.r_history.popleft()\n",
    "        \n",
    "        # return the original image with the lane superimposed\n",
    "        return self.__drawLane(corrected, l_lane, r_lane)\n",
    "    \n",
    "    def threshold(self, image):\n",
    "        \"\"\"Thresholds the input image into a binary image that highlights the lane lines.\n",
    "        \n",
    "        Args:\n",
    "            image: The image to be processed.\n",
    "            \n",
    "        Returns:\n",
    "            The thresholded binary image.\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the gray scale and saturation channel from the imput image\n",
    "        g_channel = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        s_channel = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "\n",
    "        # run both chanels through a second derivative gaussian filter\n",
    "        grad_s = LaneLine.normal8Bit(ndimage.gaussian_filter(s_channel.astype(np.float32), sigma=(35,10), order=(0,2)))\n",
    "        grad_g= LaneLine.normal8Bit(ndimage.gaussian_filter(g_channel.astype(np.float32), sigma=(35,10), order=(0,2)))\n",
    "\n",
    "        # invert the gradients to make them more presentable (white lane lines on black background)\n",
    "        grad_s  = np.max(grad_s) - grad_s\n",
    "        grad_g  = np.max(grad_g) - grad_g\n",
    "\n",
    "        # calculate a threshold based on the percentile of the filtered image\n",
    "        thresh_s = np.percentile(grad_s, 97.5)\n",
    "        thresh_g = np.percentile(grad_g, 98.6)\n",
    "\n",
    "        # binarize the image with the thresholds calculated above\n",
    "        binary_out = np.zeros_like(s_channel)\n",
    "        binary_out[(grad_s > thresh_s) | (grad_g > thresh_g)] = 1\n",
    "        \n",
    "        return binary_out\n",
    "    \n",
    "    def findLaneBases(self, image):\n",
    "        \"\"\"Looks for the most likely position of the lane line at the bottom of the input image.\n",
    "        \n",
    "        Args:\n",
    "            image: A thresholded binary image that highlights the lane lines.\n",
    "            \n",
    "        Returns:\n",
    "            The left and right lane coordinates.\n",
    "        \"\"\"\n",
    "        \n",
    "        # leave out the edges to avoid noise\n",
    "        l_buffer = 100\n",
    "        r_buffer = 100\n",
    "        \n",
    "        if len(self.l_history) > 0 and len(self.r_history) > 0:\n",
    "            \n",
    "            # if we have history and the both lanes had verified base coodinates on the previous frame\n",
    "            # then it's safe to reuse those coordinates. \n",
    "            if self.l_history[-1].hasVerifiedBaseCoordinate and self.r_history[-1].hasVerifiedBaseCoordinate:\n",
    "                return (self.l_history[-1].baseCoordinate , self.r_history[-1].baseCoordinate)\n",
    "            \n",
    "            # if just one of the lanes from the previous frame was verified, then we use it as a reference \n",
    "            # to search for the other. The thinking that the distance between lanes should not change to \n",
    "            # dramatically from frame to frame.\n",
    "            \n",
    "            if self.l_history[-1].hasVerifiedBaseCoordinate:\n",
    "                l_base_coord = self.l_history[-1].baseCoordinate \n",
    "                return (l_base_coord, self.__findRightLaneBase(image, l_base_coord, l_buffer))\n",
    "\n",
    "            if self.r_history[-1].hasVerifiedBaseCoordinate:\n",
    "                r_base_coord = self.r_history[-1].baseCoordinate \n",
    "                return (self.__findLeftLaneBase(image, r_base_coord, r_buffer), r_base_coord)\n",
    "            \n",
    "        # if we made this far then we don't have any usable historical lane posistion. So we need to \n",
    "        # find both lanes at once...\n",
    "        \n",
    "        # calculate a histogram of the bottom half of the image along the vertical axis. The peeks \n",
    "        # will indicate the most likely location of the lanes (but not always, see below)\n",
    "        histogram = np.sum(image[-int(image.shape[0]/2):,:], axis=0)\n",
    "        self.base_map = histogram\n",
    "        \n",
    "        # split the image in two halves horizontally and look for the histogram peeks on each side\n",
    "        # if the input image is thresholded well enough then this will produce a good measure of the\n",
    "        # position of our lane lines at the bottom of the image\n",
    "        center_point = int(histogram.shape[0]/2)\n",
    "        \n",
    "        # define the range of acceptable lane separation\n",
    "        min_distance = self.__target_lane_width * self.__x_scale * 0.85\n",
    "        max_distance = self.__target_lane_width * self.__x_scale * 1.1\n",
    "        \n",
    "        # get the peek from each half\n",
    "        left_max = l_buffer + np.argmax(histogram[l_buffer:center_point])\n",
    "        right_max = np.argmax(histogram[center_point:-r_buffer]) + center_point\n",
    "        lane_distance = right_max - left_max\n",
    "        \n",
    "        # check if the histogram maximums from each side fall into the acceptable lane separation zone.\n",
    "        if lane_distance > min_distance and lane_distance < max_distance:\n",
    "            return left_max, right_max\n",
    "                \n",
    "        # grab the top k maximums from each side and look for a pair with good separation\n",
    "        top_k = 25\n",
    "        l_max_ind = np.argpartition(histogram[l_buffer:center_point], -top_k)[-top_k:]\n",
    "        r_max_ind = np.argpartition(histogram[center_point:-r_buffer], -top_k)[-top_k:]\n",
    "\n",
    "        # look for a pair that fit between the min and max distance of a lane line\n",
    "        heap = []\n",
    "        for xl in l_max_ind:\n",
    "            for xr in r_max_ind:\n",
    "                distance = xr + center_point - xl\n",
    "                if distance > min_distance and distance < max_distance:\n",
    "                    error = np.absolute(self.__target_lane_width * self.__x_scale - distance)\n",
    "                    heappush(heap, (error, xl+l_buffer, xr+center_point))\n",
    "        if len(heap) > 0:\n",
    "            return heap[0][1], heap[0][2]\n",
    "        \n",
    "        return (left_max, right_max)\n",
    "    \n",
    "    def __findLeftLaneBase(self, image, right_position, buffer):\n",
    "        top_k = 25\n",
    "        center_point = int(image.shape[1]/2)\n",
    "        histogram = np.sum(image[-int(image.shape[0]/2):,buffer:center_point], axis=0)\n",
    "        l_max_ind = np.argpartition(histogram, -top_k)[-top_k:]\n",
    "        \n",
    "        min_distance = self.currentLaneWidth * self.__x_scale * 0.85\n",
    "        max_distance = self.currentLaneWidth * self.__x_scale * 1.1\n",
    "        \n",
    "        # look for a pair that fit between the min and max distance of a lane line\n",
    "        heap = []\n",
    "        for xl in l_max_ind:\n",
    "            distance = right_position - xl\n",
    "            if distance > min_distance and distance < max_distance:\n",
    "                error = np.absolute(self.currentLaneWidth * self.__x_scale - distance)\n",
    "                heappush(heap, (error, xl))\n",
    "                \n",
    "        if len(heap) == 0: \n",
    "            return right_position - self.currentLaneWidth * self.__x_scale\n",
    "        \n",
    "        return (heap[0][1] + buffer)\n",
    "        \n",
    "    def __findRightLaneBase(self, image, left_position, buffer):\n",
    "        top_k = 25\n",
    "        center_point = int(image.shape[1]/2)\n",
    "        histogram = np.sum(image[-int(image.shape[0]/2):,center_point:-buffer], axis=0)\n",
    "        r_max_ind = np.argpartition(histogram, -top_k)[-top_k:]\n",
    "        \n",
    "        min_distance = self.currentLaneWidth * self.__x_scale * 0.85\n",
    "        max_distance = self.currentLaneWidth * self.__x_scale * 1.1\n",
    "        \n",
    "        # look for a pair that fit between the min and max distance of a lane line\n",
    "        heap = []\n",
    "        for xr in r_max_ind:\n",
    "            distance = center_point - left_position + xr\n",
    "            if distance > min_distance and distance < max_distance:\n",
    "                error = np.absolute(self.currentLaneWidth * self.__x_scale - distance)\n",
    "                heappush(heap, (error, xr))\n",
    "                \n",
    "        if len(heap) == 0: \n",
    "            return left_position + self.currentLaneWidth * self.__x_scale\n",
    "        \n",
    "        return (heap[0][1] + center_point)\n",
    "    \n",
    "    def __drawLane(self, image, left, right):\n",
    "        \n",
    "        y = np.arange(0, image.shape[0], 1)\n",
    "        x_left = np.polyval(left.fit_coefficients, y)\n",
    "        x_right = np.polyval(right.fit_coefficients, y)\n",
    "\n",
    "        lane_fill = np.zeros(shape=image.shape[0:2], dtype=np.uint8)\n",
    "        lane_fill = np.dstack((lane_fill, lane_fill, lane_fill))\n",
    "\n",
    "        left_points = np.array([np.transpose(np.vstack((x_left, y)))])\n",
    "        right_points = np.array([np.flipud(np.transpose(np.vstack((x_right, y))))])\n",
    "        all_points = np.hstack((left_points, right_points))\n",
    "\n",
    "        cv2.fillPoly(lane_fill, np.int_(all_points), (0, 255, 0))\n",
    "        unwarped = self.camera.fromBirdsEye(lane_fill)\n",
    "        result = cv2.addWeighted(image, 1, unwarped, 0.3, 0)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        offset_direction = 'left' if self.currentLaneOffset > 0 else 'right'\n",
    "        currvature_text = 'Curvature: {0:0.3f} km ({1})'.format(np.absolute(self.currentLaneCurvature)/1000, self.currvatureDirection)\n",
    "        offset_text = 'Offset: {0:0.3f} m ({1} of center)'.format(np.absolute(self.currentLaneOffset), offset_direction)\n",
    "        cv2.putText(result,currvature_text,(10,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(result,offset_text,(10,90), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "def chessboardFrames():\n",
    "    \n",
    "    # read the chessboard calibration images into a list\n",
    "    chessboardFrames = []\n",
    "    file_dir = './udacity/CarND-Advanced-Lane-Lines-master/camera_cal'\n",
    "    files = os.listdir(file_dir)\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            chessboardFrames.append(mpimg.imread(file_dir + '/' + file))\n",
    "            \n",
    "    return chessboardFrames\n",
    "\n",
    "def chessboardGridSize():\n",
    "    return (9,6)\n",
    "\n",
    "def birdsEyeSourcePoints():\n",
    "    return np.float32([[202,719], [578,460], [703,460], [1110,719]])\n",
    "\n",
    "def birdsEyeDestinationPoints():\n",
    "    return np.float32([[302,719], [302,0], [1010,0], [1010,719]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing process.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process.py\n",
    "\n",
    "import cv2\n",
    "from camera import Camera\n",
    "from matplotlib import image as mpimg\n",
    "from road import *\n",
    "from data import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# 1) create the camera object and calibrate it\n",
    "print(\"Calibrating camera...\")\n",
    "camera = Camera()\n",
    "camera.calibrateDistortion(chessboardFrames(), chessboardGridSize())\n",
    "camera.calibrateBirdsEye(birdsEyeSourcePoints(), birdsEyeDestinationPoints())\n",
    "\n",
    "# 2) create the road and have it process our images\n",
    "print(\"Building road object...\")\n",
    "road = Road(camera)\n",
    "\n",
    "# 3) Process the video\n",
    "output = './udacity/CarND-Advanced-Lane-Lines-master/project_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"./udacity/CarND-Advanced-Lane-Lines-master/project_video.mp4\")\n",
    "out_clip = clip1.fl_image(road.processFrame)\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
